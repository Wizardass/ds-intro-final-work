# Введение в Data Science
## Финальная работа

***Постановка задачи.***

**Исходные данные:**

*ga_sessions.csv* - информация об уникальных сессиях пользователей: 1860042 x 18.

*ga_hits.csv* - информация о действиях пользователей 15726470 x 11.

**Задача:**

Создать сервис для прогнозирования совершения целевого действия пользователем сайта (на вход принимаются данные, аналогичные строке из датасета ga_sessions.csv, ответ - прогноз совершения целевого действия).

***Требования к выполнению:***

ROC AUC - не менее 0.65.

Формат ответа - бинарный (0/1).

Скорость ответа сервиса - не более 3 сек.

Формат файла — (минимум) .py-скрипт с инструкцией по локальному запуску или (максимум) localhost web app.

#### Файл 'Step by step.ipynb' представляет собой Jupyter Notebook, содержащий последовательные этапы работы с данными. В этом файле проводится детальное рассмотрение шагов по обработке данных, очистке от шума, а также созданию и инженерии признаков для последующего анализа и построения модели.
***Подготовка к моделированию.***

**Собираем данные в 1 датасет:**
Определяем целевое действие (события типа «Оставить заявку» и «Заказать звонок»
(ga_hits.event_action in ['sub_car_claim_click', 'sub_car_claim_submit_click',
'sub_open_dialog_click', 'sub_custom_question_submit_click',
'sub_call_number_click', 'sub_callback_submit_click', 'sub_submit_success',
'sub_car_request_submit_click'])) как 1.

* К датасету ga_sessions добавляем столбец из датасета ga_hits, сгруппированного по номеру сессии.
* Смотрим на полноту данных.
* Избавляемся от практически пустых или непоказательных столбцов ('device_model', 'utm_keyword').
* Далее работаем с каждым из столбцов, где есть пропущенные значения.
* После из уже имеющихся данных создаём дополнительные для нас фичи (разделяем дату, преобразуем размер экрана, создаём столбцы с координатами городов).
* Так же объединяем мелкие категории в категориальных признаках по принципу: если значение встречается менее 750 раз, меняем это значение на 'rare'.
* Выполняем стандартизацию количественных признаков с помощью StandardScaler и кодирование категориальных признаков с использованием OneHotEncoder. 
* Столбцы с обработанными данными и преобразованными признаками исключаются из набора данных.
* Сохраняем дата сет для будущего моделирования.


#### Файл 'pipeline.py' представляет собой скрипт на Python, реализующий пайплайн для обработки данных, построения модели и сохранения обученной модели для дальнейшего использования.
***Описание ключевых элементов файла 'pipeline.py':***

**Импорт библиотек и модулей:**
Импортируются необходимые библиотеки, такие как pandas, scikit-learn, geopy, а также модули для работы с датой и временем, логгированием и сериализацией данных.

**Функции обработки данных:**
В файле определено несколько функций для предобработки данных, которые выполняют различные преобразования и очистку, такие как изменение регистра, определение бренда устройства, 
обработка пропущенных значений, извлечение новых признаков и другие.

**Создание пайплайна:**
Основная функция main() выполняет последовательность шагов: загрузка данных, их обработка через определенные функции, построение пайплайна с использованием модели RandomForestClassifier, 
обучение модели на данных и сохранение обученного пайплайна в файл "sber_pipe.pkl".

#### Файл main.py представляет собой веб-сервис, который использует FastAPI для создания API. Он загружает предварительно обученную модель машинного обучения из файла sber_pipe.pkl, а затем предоставляет два эндпоинта для взаимодействия с моделью.

**/status (GET запрос)**

*Данный эндпоинт возвращает строку "I'm okay". Служит для проверки работоспособности сервера.*

**/predict (POST запрос)**

*Данный эндпоинт ожидает POST запрос с данными, структура которых описана в классе Form, который содержит информацию о клиенте, его действиях и контексте сессии.
Данные из POST запроса преобразуются в Pandas DataFrame, который затем передается в предварительно загруженную модель машинного обучения (model).
После прогнозирования моделью возвращается ответ с результатом предсказания и идентификатором клиента в формате JSON.*

#### Файл json_request.py представляет скрипт Python, который загружает модель, использует ее для прогнозирования на данных из JSON-файла и выводит результат прогноза.

